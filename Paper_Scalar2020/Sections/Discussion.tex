\section{General formula for the $M$-matrix of a finite period graph} \label{sec:Discussion}
Having obtained the quantum graph problem \eqref{eq:QGFullSystem}, we now turn our attention to its eigenvalues $\omega^2$.
The advantage of \eqref{eq:WholeSpaceLaplaceEqn} in comparison to \eqref{eq:QGFullSystem} is that we can now use the $M$-matrix (introduced in section \ref{ssec:MMatrix}) as a tool for determining the spectrum of \eqref{eq:WholeSpaceLaplaceEqn}.
In this section we contextualise the theory introduced in section \ref{sec:QuantumGraphs}, and in particular section \ref{ssec:MMatrix}, showing how it is employed for studying the spectrum of \eqref{eq:WholeSpaceLaplaceEqn}.
In doing so, we will also provide a general formula for the $M$-matrix of a finite period graph on which \eqref{eq:QGFullSystem} is posed.
We will follow up on this in section \ref{sec:Examples}, where we provide some explicit examples of quantum graph problems that can be solved by employing the $M$-matrix in the manner discussed below.

\subsection{General formula for the $M$-matrix} \label{ssec:MMatrixResult}
\begin{prop}[$M$-matrix entries] \label{prop:M-MatrixEntries}
	Let $\graph=\bracs{\vertSet,\edgeSet}$ be an embedded graph on which the problem \eqref{eq:QGFullSystem} is posed.
	Suppose that $\dmap u = e_k$ where $e_k$ is the $k$\textsuperscript{th} canonical unit vector in $\complex^{\abs{\vertSet}}$.
	Then the $j$\textsuperscript{th} entry of $\nmap u$, and hence the $jk$\textsuperscript{th} entry in the $M$-matrix, is given by
	\begin{align*}
		\bracs{\nmap u}_j &= 
		\begin{cases}
			0,	
			& j \not\con k, \\[5pt]
			\sum_{j\conLeft k} \omega \e^{\rmi\qm_{jk}l_{jk}} \csc\bracs{l_{jk}\omega} 
			+ \sum_{j\conRight k} \omega \e^{-\rmi\qm_{kj}l_{kj}} \csc\bracs{l_{kj}\omega},
			& j\neq k, \ j\con k, \\[5pt]
			- \sum_{\substack{j\con l \\ j\neq l}} \omega\cot\bracs{l_{jl}\omega}
			- 2\omega\sum_{j\conLeft j} \clbracs{ \cot\bracs{l_{jj}\omega} - \cos\bracs{\qm_{jj}l_{jj}}\csc\bracs{l_{jj}\omega} },
			& j=k.
		\end{cases}
	\end{align*}
\end{prop}
Note the choice of $j\conLeft j$ in the contributions from loops is simply a convention, $j\conRight j$ is equivalent here.
Also recall the convention for summing over $j\con k$:
\begin{align*}
	\sum_{j\con k} \omega\cot\bracs{l_{jk}\omega} &= \sum_{j\conLeft k} \omega\cot\bracs{l_{jk}\omega}	+ \sum_{j\conRight k} \omega\cot\bracs{l_{kj}\omega}
\end{align*}
\begin{proof}
	The proof below is an explicit computation, similar to that in \cite{ershova2014isospectrality} with adjustments for the dependence on $\qm$.
	
	We first write the general form of the edge solution $u_{jk}$ from \eqref{eq:QGEdgeODEs}:
	\begin{align} \label{eq:EdgeEqnGeneralSolution}
		u_{jk} &= \e^{-\rmi\qm_{jk}t}\bracs{ C_{+}^{(jk)}\e^{-\rmi\omega t} + C_{-}^{(jk)}\e^{\rmi\omega t} },
		\quad C_{+}^{(jk)}, C_{-}^{(jk)}\in\complex.
	\end{align}
	Since the $M$-matrix maps $\complex^{\abs{\vertSet}}$ to $\complex^{\abs{\vertSet}}$, it is sufficient to determine its action on the canonical basis of $\complex^{\abs{\vertSet}}$.
	So for each fixed $k\in\clbracs{1,...,\abs{\vertSet}}$ we set $\dmap u = e_k$.
	This provides us with sufficient Dirichlet data to solve \eqref{eq:QGEdgeODEs} on each edge and eliminate the constants $C_{+}^{(jk)}$, $C_{-}^{(jk)}$ in \eqref{eq:EdgeEqnGeneralSolution}, obtaining
	\begin{align*}
		j\not\con k &\implies
		\begin{cases}
			u_{jk}(t) = 0, \\
			u_{kj}(t) = 0,
		\end{cases} \\
		j\neq k, \ j\con k &\implies
		\begin{cases}
			u_{jk}(t) = \e^{-\rmi\qm_{jk}\bracs{t-l_{jk}}}\csc\bracs{\omega l_{jk}}\sin\bracs{\omega t}, \\
			u_{kj}(t) = \e^{-\rmi\qm_{kj}t}\csc\bracs{\omega l_{kj}}\sin\bracs{\omega \bracs{l_{kj}-t}},
		\end{cases} \\
		j = k &\implies 
		\begin{cases}
			u_{jj}(t) = \e^{-\rmi\qm_{jj}t} \bracs{ \e^{-\rmi\omega t} + \sqbracs{\e^{\rmi\qm_{jj}l_{jj}}-\e^{-\rmi\omega l_{jj}}}\csc\bracs{\omega l_{jj}}\sin\bracs{\omega t}  },
		\end{cases}
	\end{align*}
	This in turn enables us to explicitly differentiate the expressions for $u_{jk}$, and read off the values of $\bracs{\pdiff{}{n}+\rmi\qm_{jk}}u_{jk}$ at the vertices.
	In the case $j\not\con k$, we obviously get zero contribution from the edges $I_{jk}$ and $I_{kj}$.
	The case $j\neq k, \ j\con k$, yields the following contributions from the edges $I_{jk}$ and $I_{kj}$:
	\begin{align*}
		\bracs{\pdiff{}{n}+\rmi\qm_{jk}}u_{jk}\bracs{v_j} = -\omega \e^{\rmi\qm_{jk}l_{jk}}\csc\bracs{\omega l_{jk}}, 
		&\qquad \bracs{\pdiff{}{n}+\rmi\qm_{jk}}u_{jk}\bracs{v_k} = \omega\cot\bracs{\omega l_{jk}}, \\
		\bracs{\pdiff{}{n}+\rmi\qm_{kj}}u_{kj}\bracs{v_j} = -\omega \e^{-\rmi\qm_{kj}l_{kj}}\csc\bracs{\omega l_{kj}}, 
		&\qquad \bracs{\pdiff{}{n}+\rmi\qm_{kj}}u_{kj}\bracs{v_k} = \omega\cot\bracs{\omega l_{kj}}.
	\end{align*}
	Finally, when considering the case $j=k$, the contribution to $\bracs{\nmap u}_j$ from loops $I_{jj}$ in the graph also requires us to compute
	\begin{align*}
		-\lim_{t\rightarrow0}\bracs{u_{jj}'+i\qm_{jj}u_{jj}}(t) + \lim_{t\rightarrow l_{jj}}\bracs{u_{jj}'+i\qm_{jj}u_{jj}}(t)
		= 2\omega\bigl( \cot\bracs{\omega l_{jj}} - \cos\bracs{\qm_{jj}l_{jj}}\csc\bracs{\omega l_{jj}} \bigr).	
	\end{align*}
	We then use the formula
	\begin{align*}
		\bracs{\nmap u}_j &= -\sum_{j\con l} \bracs{\pdiff{}{n}+\rmi\qm_{jl}}u_{jl}\bracs{v_j},
	\end{align*}
	which yields the desired result.
\end{proof}

As mentioned in section \ref{ssec:MMatrix}, the eigenvalues $\omega^2$ of a quantum graph correspond to when the matrix $M\bracs{\omega^2} - A$ has zero as an eigenvalue, where $A$ is the diagonal matrix of vertex coupling constants.
In the case of \eqref{eq:QGDerivCondition}, there is a factor of $\omega^2$ multiplying the coupling constants $\alpha_j$ as they appear in the right-hand-side of the equation.
Furthermore, proposition \ref{prop:M-MatrixEntries} also demonstrates that the $M$-matrix (in the context of \eqref{eq:QGFullSystem}) can be thought of as being parametrised by $\qm$, and so we shall denote it by $M_{\qm}$ henceforth.
The dependence of $M_\qm$ on $\qm$ is due to our decision to specify our singular structure (comprising the domain which \eqref{eq:WholeSpaceLaplaceEqn} was posed) as an embedded, periodic metric graph and then apply the Gelfand transform --- as touched on in section \ref{ssec:MMatrix}.
In the following section, we continue our analysis of the $M$-matrix and outline how it can be used to recover the eigenvalues $\omega^2$ of \eqref{eq:QGFullSystem}, and thus \eqref{eq:WholeSpaceLaplaceEqn}.

\subsection{Consequences of Proposition \ref{prop:M-MatrixEntries}} \label{ssec:MMatrixConsequences}
Whilst proposition \ref{prop:M-MatrixEntries} provides an explicit form for the entries of the $M$-matrix, we can improve upon this when looking for a method for determining the spectrum of \eqref{eq:QGFullSystem}.
Indeed, we can see from proposition \ref{prop:M-MatrixEntries} that $M_\qm$ is meromorphic, and thus has the following decomposition, in which a scalar prefactor containing all the poles of $M_\qm$ is pulled out:
\begin{cory} \label{cory:M-MatrixEntriesNoPoles}
	Let $H^{(1)}_\qm\bracs{\omega}$ have entries defined by
	\begin{align*}
		\bracs{H^{(1)}_\qm}_{jk} &= 
		\begin{cases}
			\!\begin{aligned}
				&0,
			\end{aligned}			
			& j \not\con k, \\
			\!\begin{aligned}
				&\sum_{j\conLeft k} \bracs{ \omega e^{i\qm_{jk}l_{jk}} \prod_{\substack{ l\con m \\ \bracs{l,m} \neq \bracs{j,k} }}\sin\bracs{l_{lm}\omega} }
				\\ &\quad + \sum_{j\conRight k} \bracs{ \omega e^{-i\qm_{kj}l_{kj}} \prod_{\substack{l\con m \\ \bracs{l,m} \neq \bracs{j,k} }}\sin\bracs{l_{ml}\omega} },
			\end{aligned}
			& j\neq k, \ j\con k, \\
			\!\begin{aligned}
				&- \sum_{\substack{j\con l \\ j\neq l}} \bracs{ \omega\cos\bracs{l_{jl}\omega}\prod_{\substack{ m\con n \\ \bracs{m,n}\neq\bracs{j,l} }}\sin\bracs{l_{mn}\omega} }
				\\ &\quad - 2\omega\sum_{j\conLeft j} \bracs{ \sqbracs{ \prod_{\substack{l\con m \\ \bracs{l,m}\neq\bracs{j,j} }}\sin\bracs{l_{lm}\omega} }\bigl[ \cos\bracs{l_{jj}\omega} - \cos\bracs{\qm_{jj}l_{jj}} \bigr] },
			\end{aligned}
			& j=k,
		\end{cases}
	\end{align*}
	and set
	\begin{align*}
		H^{(2)}\bracs{\omega} &= \prod_{j\con k}\csc\bracs{l_{jk}\omega}.
	\end{align*}
	Then one has
	\begin{align*}
		M_\qm\bracs{\omega^2} &= H^{(2)}\bracs{\omega}H^{(1)}_\qm\bracs{\omega}.
	\end{align*}
\end{cory}
The product notation should be understood analogously to the summation notation over $j\con k$ introduced in section \ref{sec:QuantumGraphs}.
It is worth noticing that, depending on whether or not there are an even number of edges in the graph $\graph$, multiplying $H^{(1)}_\qm$ and dividing $H^{(2)}$ by a factor of $\omega$ provides an expression for $M_\qm$ as a ratio of two holomorphic functions in $\omega^2$.
Since $H^{(2)}$ contains all the poles of the entries of $M_\qm$, the matrix $H^{(1)}_\qm$ has no poles, and even has its entry $jk$ bounded (uniformly in $\omega$) by the number of (direct) connections $j\con k$.

In terms of utility in determining the spectrum of \eqref{eq:QGFullSystem}, corollary \ref{cory:M-MatrixEntriesNoPoles} provides us with the following methodology.
We are required to determine those $\omega^2$ for which the matrix $M_\qm\bracs{\omega^2}-A$ has at least one zero eigenvalue.
Let $\beta_j\bracs{\omega^2}, j\in\clbracs{1,...,\abs{\vertSet}}$ denote the eigenvalues of the matrix $M_\qm\bracs{\omega^2}-A$, as functions of $\omega^2$ - we will call the $\beta_j$ ``eigenvalue branches" of $M_\qm\bracs{\omega^2}-A$.
Also set $\widetilde{M}_\qm\bracs{\omega^2} = H^{(1)}_\qm - \omega^2 \bracs{H^{(2)}}^{-1} A$, and let $\widetilde{\beta}_j\bracs{\omega^2}, j\in\clbracs{1,...,\abs{\vertSet}}$ denote the eigenvalues of $\widetilde{M}_\qm$ which are continuous in $\omega^2$ (since this matrix, by construction, has no poles).
Then $\widetilde{M}_\qm$ has at least one zero eigenvalue at those $\omega^2$ for which there exists a $w\in\complex^{\abs{\vertSet}}$ such that
\begin{align} \label{eq:QGGenEvalSolveNoPoles}
	\widetilde{M}_\qm\bracs{\omega^2}w = 0.
\end{align}
Since the spectrum is our primary concern, we could also chose to determine these $\omega^2$ via solution to 
\begin{align} \label{eq:QGDetSolveCondition}
	\det\widetilde{M}_\qm\bracs{\omega^2} &= 0,
\end{align}
the merits of each approach (via \eqref{eq:QGGenEvalSolveNoPoles} or \eqref{eq:QGDetSolveCondition}) we will discuss in section \ref{ssec:ApproachConsiderations}.
Denote the set of $\omega^2$ that solve \eqref{eq:QGGenEvalSolveNoPoles} (or equivalently \eqref{eq:QGDetSolveCondition}) by $\sigma_\qm$.
Since $\beta_j\bracs{\omega^2} = H^{(2)}\widetilde{\beta}_j\bracs{\omega^2}$, provided $\omega_0^2\in\sigma_\qm$ is not a pole of $H^{(2)}$, we then have that $\omega_0^2$ is in the spectrum of \eqref{eq:QGFullSystem}.
If $\omega_0^2\in\sigma_\qm$ does coincide with a pole of $H^{(2)}$, then one requires that 
\begin{align*}
	\lim_{\omega\rightarrow\omega_0}H^{(2)}\bracs{\omega}\widetilde{\beta}_j\bracs{\omega^2} = 0
\end{align*}
for at least one eigenvalue branch with $\widetilde{\beta}_j\bracs{\omega_0^2}=0$, for $\omega_0^2$ to be in the spectrum of \eqref{eq:QGFullSystem}.
Corollary \ref{cory:M-MatrixEntriesNoPoles} also informs us of the poles of $H^{(2)}$, namely 
\begin{align*}
	\omega &= \frac{n\pi}{l_{jk}}, \quad j\conLeft k, \ n\in\naturals_{0},
\end{align*}
so we immediately know which (if any) $\omega_0^2\in\sigma_\qm$ correspond to poles of $H^{(2)}$, and thus require this additional check.
The problem \eqref{eq:WholeSpaceLaplaceEqn} has now been effectively reduced to a more accessible (family of) matrix-eigenvalue problem(s) for $M_\qm$, and we are presented with two approaches for determining the spectrum $\sigma_\qm$ --- either via \eqref{eq:QGGenEvalSolveNoPoles} or \eqref{eq:QGDetSolveCondition}, which we discuss in the following section.

\subsection{Considerations for the Approach to Solving \eqref{eq:QGDetSolveCondition}} \label{ssec:ApproachConsiderations}
In this section we briefly discuss the merits of determining the spectrum $\sigma_\qm$ via \eqref{eq:QGGenEvalSolveNoPoles} or \eqref{eq:QGDetSolveCondition} for a fixed $\qm$, and provide suggestions as to how one can efficiently recover the spectrum of \eqref{eq:WholeSpaceLaplaceEqn}.
We take as a baseline that one has to hand an appropriate numerical scheme for handling a generalised eigenvalue problem (a good introduction to which can be found in \cite{guttel2017nonlinear}), and so do not delve into the details of how such an algorithm would operate, instead choosing to highlight some potentially useful ideas for handling $\widetilde{M}_\qm$ in these contexts.
However it is worth mentioning that $\widetilde{M}_\qm$ is Hermitian (as can be seen from proposition \ref{prop:M-MatrixEntries} and corollary \ref{cory:M-MatrixEntriesNoPoles}), from which most numerical schemes benefit.

The task of solving via \eqref{eq:QGDetSolveCondition} for $\sigma_\qm$ requires that one to compute an expression for the determinant in terms of $\omega$, and determine those $\omega$ that make it vanish.
Of course the determinant also depends on $\qm$, and it is necessary to determine $\sigma_\qm$ for each $\qm$ (so that the union over $\qm$ can be taken).
This task can be simplified so long as \eqref{eq:QGDetSolveCondition} can have $\omega$ and $\qm$ separated, that is be written equivalently as
\begin{align*}
	F\bracs{\omega} &= G\bracs{\qm}
\end{align*}
for some (continuous) functions $F$ and $G$.
In this case, one can simply compute the range of $G$ and find $\omega$ satisfying the bounds
\begin{align*}
	\min\clbracs{G(\qm)} \leq F\bracs{\omega} \leq \max\clbracs{G(\qm)},
\end{align*}
netting the union $\bigcup_{\qm}\sigma_\qm$ of \eqref{eq:WholeSpaceLaplaceEqn} in one inequality.
This is an approach that we employ in our examples in section \ref{sec:Examples}.
If such a separation is impossible, one could still attempt to solve the resulting expression and obtain $\sigma_\qm$, and take the union over $\qm$.
Solution may even be possible numerically, although this may require extensive analytic work to find an expression for the determinant that is suitable for a root-finding scheme to work with, and one should consider the alternative approach below in this case.
One could instead determine $\sigma_\qm$ by working from the (generalised) eigenvalue problem \eqref{eq:QGGenEvalSolveNoPoles}, seeking eigenpairs $\bracs{\omega^2, w}\in\complex\times\complex^{\abs{\vertSet}}$.
This approach is much better suited when relying on a numerical solver, as working with the determinant directly is prone to instabilities, although of course one only obtains an approximation to $\sigma_\qm$.
Then by varying $\qm$ over a suitable mesh, an approximation to $\bigcup_{\qm}\sigma_\qm$ can be obtained.

Given that we have two approaches to determine $\sigma_\qm$, the next question to consider is when one approach is preferable to the other.
This is answered predominantly by noticing that proposition \ref{prop:M-MatrixEntries} tells us that the complexity of the entry of $\bracs{M_\qm}_{jk}$ (hence of $\bracs{\widetilde{M}_\qm}_{jk}$) depends on the number of edges between the vertices $v_j$ and $v_k$, whilst the complexity of the diagonal entries depends on the degree of the vertex $v_j$.
Furthermore, the number of vertices in the graph determines the dimensions of $\widetilde{M}_\qm$, and the sparsity of $\widetilde{M}_\qm$ depends on the number of pairs of vertices that are not (directly) connected by an edge.
This leads to the colloquial rule that ``graphs with a small number of edges lend themselves to the first approach (via \eqref{eq:QGDetSolveCondition}), whilst graphs with a large number of edges are easier to handle with approach two (via \eqref{eq:QGGenEvalSolveNoPoles})".
Indeed, as the entries of $\widetilde{M}_\qm$ grow more complex and $\widetilde{M}_\qm$ becomes less sparse, computing the determinant in \eqref{eq:QGDetSolveCondition} becomes less tangible analytically (and even more inadvisable numerically).

Another point of discussion is how to determine whether $\omega_0\in\sigma_\qm$ is an eigenvalue of \eqref{eq:QGFullSystem} when it coincides with a pole of $H^{(2)}$.
Where possible analytically, one could diagonalise $\tilde{M}_\qm\bracs{\omega^2}$ to read off the eigenvalue branches $\widetilde{\beta}_{j,\qm}$ as functions of $\omega^2$, and examine the limit
\begin{align*}
	\lim_{\omega\rightarrow\omega_0}H^{(2)}\bracs{\omega}\widetilde{\beta}_{j,\qm}\bracs{\omega^2}
\end{align*}
analytically, for those branches with $\widetilde{\beta}_{j,\qm}\bracs{\omega_0^2}=0$.
This quickly becomes impractical for large (in the sense of the previous paragraph) $M$-matrices, and a viable alternative would be to examine the behaviour of the relevant branch $\widetilde{\beta}_{j,\qm}$ numerically.
For example, one could adopt the following methodology:
\begin{enumerate}
	\item Fix a suitably small step size $\eps>0$.
	\item Compute the eigenvalue of $\widetilde{M}_\qm\bracs{\omega_0^2+\eps}$ closest to zero, which provides an approximation for the value $\widetilde{\beta}_{j,\qm}\bracs{\omega_0^2+\eps}$.
	\item Proceed inductively: for each $n\in\naturals$ compute an approximation to $\widetilde{\beta}_{j,\qm}\bracs{\omega_0^2+n\eps}$ by finding the eigenvalue of $\widetilde{M}_\qm\bracs{\omega_0^2+n\eps}$ closest to $\widetilde{\beta}_{j,\qm}\bracs{\omega_0^2+(n-1)\eps}$.
	\item If desired, swap $\eps$ with $-\eps$ and repeat to get a two-sided trace of $\widetilde{\beta}_{j,\qm}$.
\end{enumerate}
The idea being to attempt to ``trace" or ``follow" the branch $\widetilde{\beta}_{j,\qm}$ in a region around $\omega_0^2$, which then allows an approximation of the behaviour of $H^{(2)}\widetilde{\beta}_{j,\qm}$ near $\omega_0^2$.
Of course, this idea is not without limitations and complexities --- for example if the algebraic multiplicity of $\omega_0^2$ is greater than one, there would be the need to approximate multiple branches near $\omega_0^2$.

Our final discussion point concerns how to efficiently solve \eqref{eq:QGGenEvalSolveNoPoles} for $\sigma_\qm$ for each $\qm$ (or for each value in a suitable mesh of $\qm$ values).
This must be done to obtain the spectrum of \eqref{eq:WholeSpaceLaplaceEqn}, which (because of the Gelfand transform) we obtain from the union $\bigcup_{\qm}\sigma_\qm$.
One suggestion that comes to mind is to investigate whether the solutions $\omega$ to \eqref{eq:QGGenEvalSolveNoPoles} (or \eqref{eq:QGDetSolveCondition}) are stable with respect to changes in the $\qm$, that is whether one can obtain a result like (one of) the following:
\begin{itemize}
	\item For every $\eps>0$, there exists some $\delta>0$ such that if $\norm{\qm^{(1)}-\qm^{(2)}}<\delta$, then the solutions $\omega^{(1)}$ and $\omega^{(2)}$ to \eqref{eq:QGGenEvalSolveNoPoles} (with $\qm$ taking the values $\qm^{(1)}$ and $\qm^{(2)}$ respectively) are such that $\norm{\omega^{(1)}-\omega^{(2)}}<\eps$.
	\item There exists some $c\geq 0$ such that; if $\omega^{(1)}$ and $\omega^{(2)}$ are solutions to \eqref{eq:QGGenEvalSolveNoPoles} with $\qm$ taking the values $\qm^{(1)}$ and $\qm^{(2)}$ respectively, then
	\begin{align*}
		\norm{\qm^{(1)}-\qm^{(2)}} \leq c \norm{\omega^{(1)}-\omega^{(2)}}.
	\end{align*}
\end{itemize}
Having either of these confirmed would mean that one could adopt a more informed approach to solving \eqref{eq:QGGenEvalSolveNoPoles} on a $\qm$-mesh: after solving at $\qm^{(1)}$ and obtaining a solution $\omega^{(1)}$, and knowing the next mesh-point $\qm^{(2)}$ to be solved at, the value $\omega^{(1)}$ would provide a good starting guess to an algorithm determining the solution of \eqref{eq:QGGenEvalSolveNoPoles} at $\qm^{(2)}$.
By providing an informed ``initial guess" in this way, a numerical method should require less time to converge to a solution, and thus require less time to reconstruct the spectrum of \eqref{eq:WholeSpaceLaplaceEqn}.
Of course this suggestion also assumes that one is using a numerical method that relies on stepping through a $\qm$-mesh in the first place, and if other methods that do not rely on such an approach can be used, they would not benefit in the same way as suggested here.
\tstk{Final sentence here like ``the authors would be interested to hear of any known theory or developments in this area"? Or just leave the point as it is and start the next section?}